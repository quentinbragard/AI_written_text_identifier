{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use transfer-learning with huggingface-transformers library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and make it accessible for huggingface environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from transformers import (AutoTokenizer, \n",
    "                          TFAutoModel,\n",
    "                          TFAutoModelForSequenceClassification\n",
    "                          )\n",
    "from datasets import Dataset, DatasetDict, load_from_disk, load_dataset # to use huggingface datasets\n",
    "from detector.utils import load_data, divide_frame\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks, Model\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit, RandomizedSearchCV\n",
    "from joblib import dump, load\n",
    "\n",
    "transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices() # to see if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset csv (/Users/michaelfiedler/.cache/huggingface/datasets/aadityaubhat___csv/aadityaubhat--GPT-wiki-intro-10ad8b711a5f3880/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AI</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sexhow railway station was a railway station l...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Finnish folklore, all places and things, an...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In mathematics, specifically differential calc...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is a Japanese shōjo manga series written and i...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robert Milner \"Rob\" Bradley, Jr. (born August ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>Randy Borum is a Professor and Coordinator of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>Sa'och (, also, \"Sauch\") is an endangered, nuc...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>Philip C. Hanawalt (born 1931) is an American ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>Vossius Gymnasium is a public gymnasium in the...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>Simone Stratigo (, Symeon Filippos Stratigos; ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  AI version\n",
       "0       Sexhow railway station was a railway station l...   1    gpt3\n",
       "1       In Finnish folklore, all places and things, an...   1    gpt3\n",
       "2       In mathematics, specifically differential calc...   1    gpt3\n",
       "3       is a Japanese shōjo manga series written and i...   1    gpt3\n",
       "4       Robert Milner \"Rob\" Bradley, Jr. (born August ...   1    gpt3\n",
       "...                                                   ...  ..     ...\n",
       "149995  Randy Borum is a Professor and Coordinator of ...   1    gpt3\n",
       "149996  Sa'och (, also, \"Sauch\") is an endangered, nuc...   1    gpt3\n",
       "149997  Philip C. Hanawalt (born 1931) is an American ...   1    gpt3\n",
       "149998  Vossius Gymnasium is a public gymnasium in the...   1    gpt3\n",
       "149999  Simone Stratigo (, Symeon Filippos Stratigos; ...   1    gpt3\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load gpt3 outputs from huggingface (output is from gpt3-curie model)\n",
    "gpt_simple = load_dataset('aadityaubhat/GPT-wiki-intro')\n",
    "gpt_simple.set_format(type='pandas')\n",
    "df_gpt3 = pd.DataFrame(columns=['text', 'AI'])\n",
    "df_gpt3['text'] = gpt_simple['train']['generated_intro']\n",
    "df_gpt3['AI'] = 1\n",
    "df_gpt3[\"version\"] = \"gpt3\"\n",
    "df_gpt3.to_csv(\"gpt3_output/gpt3_simple.csv\", index=False)\n",
    "df_gpt3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data I created using the OpenAI API (approx. 23_600 samples)\n",
    "df_gpt3_advanced = pd.read_csv(\"gpt3_output/gpt3_advanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AI</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington D.C. - In the midst of a polarizing...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Science: The Key to Our Future\\n\\nScience has ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Local High School Wins State Championship in B...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mathematics: More Than Just Numbers\\n\\nMathema...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tragic Car Accident Claims Three Lives\\n\\nIn a...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23649</th>\n",
       "      <td>The educational system of Germany\\n\\nGermany i...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23650</th>\n",
       "      <td>The educational system in Finland is often tou...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23651</th>\n",
       "      <td>Education is an essential aspect of any societ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23652</th>\n",
       "      <td>The educational system of Germany is one of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23653</th>\n",
       "      <td>As a student, it's important to understand the...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23654 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  AI version\n",
       "0      Washington D.C. - In the midst of a polarizing...   1  gpt3.5\n",
       "1      Science: The Key to Our Future\\n\\nScience has ...   1  gpt3.5\n",
       "2      Local High School Wins State Championship in B...   1  gpt3.5\n",
       "3      Mathematics: More Than Just Numbers\\n\\nMathema...   1  gpt3.5\n",
       "4      Tragic Car Accident Claims Three Lives\\n\\nIn a...   1  gpt3.5\n",
       "...                                                  ...  ..     ...\n",
       "23649  The educational system of Germany\\n\\nGermany i...   1  gpt3.5\n",
       "23650  The educational system in Finland is often tou...   1  gpt3.5\n",
       "23651  Education is an essential aspect of any societ...   1  gpt3.5\n",
       "23652  The educational system of Germany is one of th...   1  gpt3.5\n",
       "23653  As a student, it's important to understand the...   1  gpt3.5\n",
       "\n",
       "[23654 rows x 3 columns]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt3_advanced[\"version\"] = \"gpt3.5\" # add version to later analyze on which outputs the model performs better\n",
    "df_gpt3_advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data() # load original data originate from OpenAI with human text and GPT2 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = (data[\"train\"].reset_index(drop=True), \n",
    "                    data[\"valid\"].reset_index(drop=True), \n",
    "                    data[\"test\"].reset_index(drop=True))\n",
    "\n",
    "\n",
    "def remove_newline(text: str) -> str:\n",
    "    return text.replace(\"\\n\", \" \")\n",
    "\n",
    "for df in [train, val, test]:\n",
    "    df[\"version\"] = np.where(df[\"AI\"] ==1, \"gpt2\", \"human\")\n",
    "    \n",
    "for df in [train, val, test, df_gpt3, df_gpt3_advanced]:\n",
    "    df[\"text\"] = df[\"text\"].apply(remove_newline)\n",
    "    df[\"text_length\"] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AI</th>\n",
       "      <th>version</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generative AI, also known as creative AI, is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Science: Advancements and Discoveries in the F...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The education system of Finland is known as on...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sports have been an integral part of human soc...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tragic Car Accident Claims Three Lives  On Fri...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23649</th>\n",
       "      <td>Artificial intelligence (AI) has seen tremendo...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23650</th>\n",
       "      <td>Title: Local High School Wins State Championsh...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23651</th>\n",
       "      <td>Generative AI Revolutionizes Creative Industri...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23652</th>\n",
       "      <td>Introduction:  Education is one of the crucial...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23653</th>\n",
       "      <td>The war in Ukraine has been ongoing since 2014...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23654 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  AI version  \\\n",
       "0      Generative AI, also known as creative AI, is a...   1  gpt3.5   \n",
       "1      Science: Advancements and Discoveries in the F...   1  gpt3.5   \n",
       "2      The education system of Finland is known as on...   1  gpt3.5   \n",
       "3      Sports have been an integral part of human soc...   1  gpt3.5   \n",
       "4      Tragic Car Accident Claims Three Lives  On Fri...   1  gpt3.5   \n",
       "...                                                  ...  ..     ...   \n",
       "23649  Artificial intelligence (AI) has seen tremendo...   1  gpt3.5   \n",
       "23650  Title: Local High School Wins State Championsh...   1  gpt3.5   \n",
       "23651  Generative AI Revolutionizes Creative Industri...   1  gpt3.5   \n",
       "23652  Introduction:  Education is one of the crucial...   1  gpt3.5   \n",
       "23653  The war in Ukraine has been ongoing since 2014...   1  gpt3.5   \n",
       "\n",
       "       text_length  \n",
       "0             1605  \n",
       "1             2301  \n",
       "2             1177  \n",
       "3              674  \n",
       "4             1071  \n",
       "...            ...  \n",
       "23649          661  \n",
       "23650         1865  \n",
       "23651         1061  \n",
       "23652         1135  \n",
       "23653         1574  \n",
       "\n",
       "[23654 rows x 4 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample all data but with no order (which is due to the fact how I called the OpenAI API to retrieve the data)\n",
    "df_gpt3_advanced = df_gpt3_advanced.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "df_gpt3_advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gpt3 outputs to the original data\n",
    "train = pd.concat([train, df_gpt3.iloc[:140_000, :], df_gpt3_advanced.iloc[:-5000,:]])\n",
    "val = pd.concat([val, df_gpt3.iloc[140_000:145_000,:], df_gpt3_advanced.iloc[-5000:-2500,:]])\n",
    "test = pd.concat([test, df_gpt3.iloc[145_000:,:], df_gpt3_advanced.iloc[-2500:,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 70_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data to have 50 % human text and 50 % AI text where AI text is divided into 25 % gpt2, 25 % gpt3, 50 % gpt3.5\n",
    "train_sample = pd.concat(\n",
    "                    [train[train.version == \"human\"].sample(n=train_size//2, random_state=1),\n",
    "                    train[train.version == \"gpt2\"].sample(n=train_size//8, random_state=1),\n",
    "                    train[train.version == \"gpt3\"].sample(n=train_size//8, random_state=1),\n",
    "                    train[train.version == \"gpt3.5\"].sample(n=train_size//4, random_state=1)]\n",
    "                    ).reset_index(drop=True)\n",
    "val = pd.concat([val[val.version == \"human\"].sample(5000, random_state=1),\n",
    "                 val[val.version == \"gpt2\"].sample(1250, random_state=1),\n",
    "                 val[val.version == \"gpt3\"].sample(1250, random_state=1),\n",
    "                 val[val.version == \"gpt3.5\"].sample(2500, random_state=1)]).reset_index(drop=True)\n",
    "test = pd.concat([test[test.version == \"human\"].sample(5000, random_state=1),\n",
    "                 test[test.version == \"gpt2\"].sample(1250, random_state=1),\n",
    "                 test[test.version == \"gpt3\"].sample(1250, random_state=1),\n",
    "                 test[test.version == \"gpt3.5\"].sample(2500, random_state=1)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AI</th>\n",
       "      <th>version</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drereichdude's Thoughts:  This is one of my fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duration (Minutes)When current flows through w...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># !/usr/bin/env python  '''  NAME  ghc-coloriz...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think Azure Logic Apps is a great way to imp...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>4309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recipe for a vegan Falafel Burger with avocado...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>3989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>Machine learning is an exciting field of compu...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>Mathematics is a fundamental subject that has ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>Mathematics, often referred to as the language...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>2075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>Sports have been a fundamental aspect of human...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>Three Injured in Car Accident on Main Street  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  AI version  \\\n",
       "0      drereichdude's Thoughts:  This is one of my fa...   0   human   \n",
       "1      Duration (Minutes)When current flows through w...   0   human   \n",
       "2      # !/usr/bin/env python  '''  NAME  ghc-coloriz...   0   human   \n",
       "3      I think Azure Logic Apps is a great way to imp...   0   human   \n",
       "4      Recipe for a vegan Falafel Burger with avocado...   0   human   \n",
       "...                                                  ...  ..     ...   \n",
       "69995  Machine learning is an exciting field of compu...   1  gpt3.5   \n",
       "69996  Mathematics is a fundamental subject that has ...   1  gpt3.5   \n",
       "69997  Mathematics, often referred to as the language...   1  gpt3.5   \n",
       "69998  Sports have been a fundamental aspect of human...   1  gpt3.5   \n",
       "69999  Three Injured in Car Accident on Main Street  ...   1  gpt3.5   \n",
       "\n",
       "       text_length  \n",
       "0             1714  \n",
       "1              572  \n",
       "2             3126  \n",
       "3             4309  \n",
       "4             3989  \n",
       "...            ...  \n",
       "69995         1091  \n",
       "69996          716  \n",
       "69997         2075  \n",
       "69998          818  \n",
       "69999         1480  \n",
       "\n",
       "[70000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AI</th>\n",
       "      <th>version</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Behold, a virgin shall conceive, and bear a so...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>3807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Fetterman, center, the mayor of Braddock,...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>4486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is Alec Torelli?  Alec Torelli has a uniqu...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The year is 2084. If you somehow survived the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTIN, United States — \"Rejections.\" That's w...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>4788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Opening shot of a computer screen with code ru...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Introduction:  Machine learning is a subset of...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Title: The Beauty of Mathematics  Opening shot...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Introduction:  Machine learning is a field of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[Opening shot of a computer screen showing a g...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>1934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  AI version  \\\n",
       "0     Behold, a virgin shall conceive, and bear a so...   0   human   \n",
       "1     John Fetterman, center, the mayor of Braddock,...   0   human   \n",
       "2     Who is Alec Torelli?  Alec Torelli has a uniqu...   0   human   \n",
       "3     The year is 2084. If you somehow survived the ...   0   human   \n",
       "4     AUSTIN, United States — \"Rejections.\" That's w...   0   human   \n",
       "...                                                 ...  ..     ...   \n",
       "9995  Opening shot of a computer screen with code ru...   1  gpt3.5   \n",
       "9996  Introduction:  Machine learning is a subset of...   1  gpt3.5   \n",
       "9997  Title: The Beauty of Mathematics  Opening shot...   1  gpt3.5   \n",
       "9998  Introduction:  Machine learning is a field of ...   1  gpt3.5   \n",
       "9999  [Opening shot of a computer screen showing a g...   1  gpt3.5   \n",
       "\n",
       "      text_length  \n",
       "0            3807  \n",
       "1            4486  \n",
       "2             543  \n",
       "3            1136  \n",
       "4            4788  \n",
       "...           ...  \n",
       "9995         1884  \n",
       "9996         1171  \n",
       "9997         1834  \n",
       "9998         1131  \n",
       "9999         1934  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AI</th>\n",
       "      <th>version</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Researchers over at Check Point Security have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>2540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glass et al. (1989) reported a 16-year-old boy...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>4196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(You may have been directed here from www.ke0o...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This tournament is a 1v1 Joust where everyone ...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand Prize - $100,000  The M-Prize Winner is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Generative AI: The Future of Artificial Intell...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Title: Local High School Takes Home Championsh...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Introduction:  Politics is an arena that is fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Innovative Education System in Finland  Finlan...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Science is a field of study that deals with th...</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt3.5</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  AI version  \\\n",
       "0     Researchers over at Check Point Security have ...   0   human   \n",
       "1     Glass et al. (1989) reported a 16-year-old boy...   0   human   \n",
       "2     (You may have been directed here from www.ke0o...   0   human   \n",
       "3     This tournament is a 1v1 Joust where everyone ...   0   human   \n",
       "4     Grand Prize - $100,000  The M-Prize Winner is ...   0   human   \n",
       "...                                                 ...  ..     ...   \n",
       "9995  Generative AI: The Future of Artificial Intell...   1  gpt3.5   \n",
       "9996  Title: Local High School Takes Home Championsh...   1  gpt3.5   \n",
       "9997  Introduction:  Politics is an arena that is fi...   1  gpt3.5   \n",
       "9998  Innovative Education System in Finland  Finlan...   1  gpt3.5   \n",
       "9999  Science is a field of study that deals with th...   1  gpt3.5   \n",
       "\n",
       "      text_length  \n",
       "0            2540  \n",
       "1            4196  \n",
       "2            1111  \n",
       "3            1816  \n",
       "4             309  \n",
       "...           ...  \n",
       "9995         2283  \n",
       "9996         2108  \n",
       "9997         2165  \n",
       "9998         2367  \n",
       "9999         2251  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just to have a look at the data\n",
    "display(train_sample)\n",
    "display(val)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "version\n",
       "human     5000\n",
       "gpt3.5    2500\n",
       "gpt2      1250\n",
       "gpt3      1250\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data counts\n",
    "val.version.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_small, train_medium, train_long = divide_frame(train)\n",
    "# for df in [train_small, train_medium, train_long]:\n",
    "#     print(df.shape[0])\n",
    "\n",
    "# train_sample = pd.concat([train_small.sample(20_000, random_state=1), \n",
    "#                           train_medium.sample(30_000, random_state=1),\n",
    "#                           train_long.sample(20_000, random_state=1)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataset objects from the dataframes to use them with the huggingface library\n",
    "ds_train = Dataset.from_pandas(train_sample, split=\"train\")\n",
    "ds_val = Dataset.from_pandas(val, split=\"valid\")\n",
    "ds_test = Dataset.from_pandas(test, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack datasets into a dictionary to tokenize them in parallel\n",
    "ds_dict = DatasetDict({\"train\": ds_train, \"valid\": ds_val, \"test\": ds_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length'],\n",
       "        num_rows: 70000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "# save the data to disk (not needed when already done)\n",
    "ds_dict.save_to_disk(f\"preprocessed_data_{train_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length'],\n",
       "        num_rows: 70000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data from disk (to save time when running the notebook again)\n",
    "ds_dict = load_from_disk(f\"preprocessed_data_{train_size}\")\n",
    "ds_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tokenizer suitable for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('extractors_tokenizer_roberta-large/tokenizer_config.json',\n",
       " 'extractors_tokenizer_roberta-large/special_tokens_map.json',\n",
       " 'extractors_tokenizer_roberta-large/vocab.json',\n",
       " 'extractors_tokenizer_roberta-large/merges.txt',\n",
       " 'extractors_tokenizer_roberta-large/added_tokens.json',\n",
       " 'extractors_tokenizer_roberta-large/tokenizer.json')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_checkpoint(name: str=\"distilbert\", \n",
    "                     large: bool=True,\n",
    "                     uncased: bool=True) -> str:\n",
    "    model_ckpt = f'{name}-large' if large else f'{name}-base'\n",
    "    return f'{model_ckpt}-uncased' if uncased else model_ckpt\n",
    "\n",
    "model_ckpt = model_checkpoint(name=\"roberta\",large=True, uncased=False)\n",
    "# define the tokenizer the model was trained with\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "tokenizer.save_pretrained(f\"extractors_tokenizer_{model_ckpt}\") # faster for prediction\n",
    "#model_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 20:07:15.670406: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-06-25 20:07:15.671630: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-06-25 20:07:15.671657: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-06-25 20:07:15.672105: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-25 20:07:15.673813: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[   0, 9226,   16,   10, 1296,  328,    2]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"this is a test!\", return_tensors=\"tf\") # just to see how the tokenizer works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names # to see what the model expects as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tokenize function that tokenizes the text in batches\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "# encode the data; only run when not yet done\n",
    "ds_encoded = ds_dict.map(tokenize, batched=True, batch_size=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "# save the encoded data to disk (not needed when already done)\n",
    "ds_encoded.save_to_disk(f\"encoded_data_{train_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from disk (to save time when running the notebook again)\n",
    "ds_encoded = load_from_disk(f\"encoded_data_{train_size}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Use pre-trained model as feature extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting last hidden layer of a BERT model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this approach the model-weights of our RoBERTA model are frozen and provide features for a classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model to use from huggingface\n",
    "model = TFAutoModel.from_pretrained(model_ckpt, from_pt=True) # load the model from the checkpoint\n",
    "model.save_pretrained(f\"extractors_model_{model_ckpt}\") # save model on disk to predict faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(1, 6, 1024), dtype=float32, numpy=\n",
       "array([[[ 0.04603524, -0.00462841,  0.01070017, ..., -0.05166832,\n",
       "          0.10207281,  0.06168523],\n",
       "        [ 0.16665468, -0.10331246, -0.35997272, ...,  0.06356603,\n",
       "         -0.1478664 ,  0.08259304],\n",
       "        [ 0.36435974, -0.06037583, -0.32145458, ...,  0.09165369,\n",
       "          0.07294382,  0.12116899],\n",
       "        [-0.08846132, -0.09831417,  0.01492194, ..., -0.04664286,\n",
       "         -0.18895282,  0.1724447 ],\n",
       "        [ 0.07978453, -0.15301354, -0.12229724, ..., -0.16046473,\n",
       "          0.11752793,  0.00620504],\n",
       "        [ 0.06696582, -0.0087914 ,  0.03385552, ..., -0.0685569 ,\n",
       "          0.08994152,  0.01962573]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
       "array([[ 0.15439375,  0.71824986,  0.45034176, ..., -0.00599452,\n",
       "         0.40904945, -0.3544111 ]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a test\n",
    "text = \"this is a test\"\n",
    "inputs = tokenizer(text, return_tensors=\"tf\")\n",
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape #output [batch_size, n_tokens, hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for classification it is common practice use hidden state associated to start \n",
    "# of sequence token\n",
    "outputs.last_hidden_state[:, 0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract last hidden state for whole dataset\n",
    "def extract_hidden_states(batch):\n",
    "    inputs = {k: v for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "    last_hidden_state = model(**inputs).last_hidden_state\n",
    "    return {\"hidden_state\": last_hidden_state[:, 0].numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_encoded.set_format(\"tensorflow\", columns=[\"input_ids\", \"attention_mask\", \"AI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': array([[-0.3427664 , -0.28302005, -0.21823733, ...,  0.21029028,\n",
       "         -0.7165592 ,  0.48414364],\n",
       "        [-0.3774553 , -0.19625072, -0.10798267, ...,  0.48125118,\n",
       "         -0.23683989,  0.46917036]], dtype=float32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_hidden_states(ds_encoded[\"train\"][:2]) # just a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n",
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "# extract all hidden states for the whole dataset (takes long; only run when not yet done)\n",
    "# GPU recommended!\n",
    "ds_hidden = ds_encoded.map(extract_hidden_states, batched=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 70000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "# save to disk the hidden states for reuse\n",
    "ds_hidden.save_to_disk(f\"hidden_states_{model_ckpt}_{train_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hidden states from disk (to save time when running the notebook again)\n",
    "ds_hidden = load_from_disk(f\"hidden_states_{model_ckpt}_{train_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 70000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'AI', 'version', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /Users/michaelfiedler/code/michafdlr/AI_written_text_identifier/notebooks/hidden_states_roberta-large_70000/train/cache-22622a74f58005fc.arrow\n"
     ]
    }
   ],
   "source": [
    "# shuffling data (not needed, just wanted to make sure that models do not learn from the order of the data)\n",
    "ds_hidden_train_shuffled = ds_hidden[\"train\"].shuffle(seed=1)\n",
    "ds_hidden_val_shuffled = ds_hidden[\"valid\"].shuffle(seed=1)\n",
    "ds_hidden_test_shuffled = ds_hidden[\"test\"].shuffle(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AI': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 1, 0])>,\n",
       " 'input_ids': <tf.Tensor: shape=(3, 512), dtype=int64, numpy=\n",
       " array([[    0,    20,    22, ...,   172,    24,     2],\n",
       "        [    0,   510, 31497, ...,  2452,     8,     2],\n",
       "        [    0, 34447,    42, ...,     1,     1,     1]])>,\n",
       " 'attention_mask': <tf.Tensor: shape=(3, 512), dtype=int64, numpy=\n",
       " array([[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])>,\n",
       " 'hidden_state': <tf.Tensor: shape=(3, 1024), dtype=float32, numpy=\n",
       " array([[-0.21136746, -0.06436478, -0.35749552, ...,  0.27449238,\n",
       "         -0.48374236,  0.42047864],\n",
       "        [-0.2226051 , -0.1944612 , -0.14720827, ...,  0.33875376,\n",
       "         -0.49206942,  0.38407058],\n",
       "        [-0.15701647, -0.30564892, -0.19805235, ...,  0.19279474,\n",
       "         -0.17367943,  0.42932492]], dtype=float32)>}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to check it works\n",
    "ds_hidden_val_shuffled[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data to train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now using these hidden states to train a relatively simple classifier to predict if text is AI written or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(ds_hidden_train_shuffled[\"hidden_state\"])\n",
    "X_val = np.array(ds_hidden_val_shuffled[\"hidden_state\"])\n",
    "X_test = np.array(ds_hidden_test_shuffled[\"hidden_state\"])\n",
    "\n",
    "y_train = np.array(ds_hidden_train_shuffled[\"AI\"])\n",
    "y_val = np.array(ds_hidden_val_shuffled[\"AI\"])\n",
    "y_test = np.array(ds_hidden_test_shuffled[\"AI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(ds_hidden[\"train\"][\"hidden_state\"])\n",
    "# X_val = np.array(ds_hidden[\"valid\"][\"hidden_state\"])\n",
    "# X_test = np.array(ds_hidden[\"test\"][\"hidden_state\"])\n",
    "\n",
    "# y_train = np.array(ds_hidden[\"train\"][\"AI\"])\n",
    "# y_val = np.array(ds_hidden[\"valid\"][\"AI\"])\n",
    "# y_test = np.array(ds_hidden[\"test\"][\"AI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53308034, -0.23917353, -0.30839637, ...,  0.21083452,\n",
       "        -0.2365539 ,  0.4096494 ],\n",
       "       [-0.23844111, -0.16399954, -0.1715692 , ...,  0.334796  ,\n",
       "        -0.490215  ,  0.57703674],\n",
       "       [-0.06416402, -0.16005722, -0.13072658, ...,  0.36260733,\n",
       "        -0.2638023 ,  0.50358015],\n",
       "       ...,\n",
       "       [-0.36641166, -0.20664789, -0.10559689, ...,  0.44444257,\n",
       "        -0.5690878 ,  0.4653337 ],\n",
       "       [-0.35671422, -0.17738439, -0.10524814, ...,  0.24413244,\n",
       "        -0.35898906,  0.5773676 ],\n",
       "       [-0.26076144, -0.20022778, -0.13960727, ...,  0.46314907,\n",
       "        -0.32893983,  0.5128594 ]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 1024), (70000,))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_search = np.vstack((X_train, X_val))\n",
    "y_search = np.hstack((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1024) (80000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_search.shape, y_search.shape)\n",
    "split = PredefinedSplit([-1]*X_train.shape[0]+[0]*X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model_roberta = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(max_iter=3000)\n",
    "\n",
    "params = {\"C\":[2**k for k in range(2, 12)]}\n",
    "\n",
    "search = GridSearchCV(lr_clf,\n",
    "                      param_grid=params,\n",
    "                      n_jobs=-1,\n",
    "                      cv = split,\n",
    "                      scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=LogisticRegression(max_iter=3000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=LogisticRegression(max_iter=3000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=3000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=3000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=LogisticRegression(max_iter=3000), n_jobs=-1,\n",
       "             param_grid={'C': [4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 32}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf_best = LogisticRegression(max_iter=5000, C=search.best_params_[\"C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=32, max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=32, max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=32, max_iter=5000)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models_70000/lr_clf_best_roberta-large.joblib']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lr_clf_best, f\"trained_models_{train_size}/lr_clf_best_{model_ckpt}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf_best = load(f\"trained_models_{train_size}/lr_clf_best_{model_ckpt}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9623"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model_roberta[\"logistic_regression\"] = lr_clf_best.score(X_test, y_test)\n",
    "scores_model_roberta[\"logistic_regression\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = SVC(random_state=1)\n",
    "\n",
    "# params_svc = {\n",
    "#     'C': [0.5, 1, 2],\n",
    "#     #'degree': 3,\n",
    "#     'kernel': ['linear']\n",
    "#  }\n",
    "\n",
    "# search_svc = GridSearchCV(\n",
    "#     svc,\n",
    "#     param_grid=params_svc,\n",
    "#     n_jobs=-1,\n",
    "#     cv=split,\n",
    "#     scoring=\"accuracy\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_svc.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_best = search_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_best.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_clf = RandomForestClassifier(random_state=1, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_rf = {\n",
    "#  'bootstrap': [True, False],\n",
    "#  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#  'max_features': ['auto', 'sqrt'],\n",
    "#  'min_samples_leaf': [1, 2, 4],\n",
    "#  'min_samples_split': [2, 5, 10],\n",
    "#  'n_estimators': [200, 400, 600, 800, 1000]\n",
    "#  }\n",
    "\n",
    "# random_search = RandomizedSearchCV(rf_clf,\n",
    "#                                    param_distributions=params_rf,\n",
    "#                                    n_iter=5,\n",
    "#                                    scoring=\"accuracy\",\n",
    "#                                    n_jobs=-1,\n",
    "#                                    cv=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=10)]: Done 600 out of 600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=10)]: Done 600 out of 600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  5.5min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=10)]: Done 800 out of 800 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  6.7min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=10)]: Done 800 out of 800 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  7.1min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=10)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=1,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=1,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=1, verbose=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=1, verbose=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=1,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_search.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_search.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# xgb_clf = XGBClassifier(booster = 'gblinear', \n",
    "#                         n_estimators=1000, \n",
    "#                         seed=1, \n",
    "#                         random_state=1)\n",
    "# #xgb_clf.get_params()\n",
    "# params_xgb = {\n",
    "#     'reg_lambda': [k*0.1 for k in range(15)]\n",
    "#     }\n",
    "\n",
    "# search_xgb = GridSearchCV(\n",
    "#     xgb_clf,\n",
    "#     param_grid=params_xgb,\n",
    "#     n_jobs=-1,\n",
    "#     cv=split,\n",
    "#     scoring=\"accuracy\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_xgb.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_best = search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gblinear', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/xgb_best_roberta-large.joblib.dat']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump(xgb_best, f\"trained_models/xgb_best_{model_ckpt}.joblib.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_model_roberta[\"xgb\"] = xgb_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores_model_roberta[\"xgb\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.52917e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.5494e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.37585e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.13302e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.5304e-09): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifierCV(alphas=[0.03, 0.035, 0.04, 0.045],\n",
       "                  cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifierCV</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifierCV(alphas=[0.03, 0.035, 0.04, 0.045],\n",
       "                  cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifierCV(alphas=[0.03, 0.035, 0.04, 0.045],\n",
       "                  cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifierCV(alphas=[0.03, 0.035, 0.04, 0.045], cv=split)\n",
    "\n",
    "ridge_clf.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9602"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models_70000/ridge_clf_roberta-large.joblib']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(ridge_clf, f\"trained_models_{train_size}/ridge_clf_{model_ckpt}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model_roberta[\"ridge\"] = ridge_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model_roberta[\"ridge\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basic_nn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1024)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69825 (272.75 KB)\n",
      "Trainable params: 69825 (272.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_inputs = keras.Input(shape=(X_train.shape[1],))\n",
    "x = layers.Dense(64, activation='gelu', kernel_initializer=\"he_normal\")(nn_inputs)\n",
    "#x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(64, activation='gelu', kernel_initializer=\"he_normal\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "nn_model = Model(inputs=nn_inputs, outputs = outputs, name=\"basic_nn\")\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 150\n",
    "num_train_examples = X_train.shape[0]\n",
    "batch_size = 32\n",
    "init_lr = 1e-3\n",
    "\n",
    "decay_steps = num_train_examples // batch_size\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(initial_learning_rate=init_lr,\n",
    "                                                    decay_steps=decay_steps,\n",
    "                                                    decay_rate=0.9)\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor=\"val_binary_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             patience=10,\n",
    "                             restore_best_weights=True)\n",
    "\n",
    "nn_model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                 metrics=[keras.metrics.BinaryAccuracy()],\n",
    "                 optimizer = optimizers.legacy.Adam(lr_schedule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/keras/src/backend.py:5805: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-06-25 20:24:18.089832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 [==============================] - ETA: 0s - loss: 0.2278 - binary_accuracy: 0.9043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 20:25:06.268232: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2188/2188 [==============================] - 52s 23ms/step - loss: 0.2278 - binary_accuracy: 0.9043 - val_loss: 0.1564 - val_binary_accuracy: 0.9339\n",
      "Epoch 2/150\n",
      "2188/2188 [==============================] - 42s 19ms/step - loss: 0.1565 - binary_accuracy: 0.9367 - val_loss: 0.1611 - val_binary_accuracy: 0.9345\n",
      "Epoch 3/150\n",
      "2188/2188 [==============================] - 44s 20ms/step - loss: 0.1367 - binary_accuracy: 0.9456 - val_loss: 0.1278 - val_binary_accuracy: 0.9538\n",
      "Epoch 4/150\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.1233 - binary_accuracy: 0.9513 - val_loss: 0.1448 - val_binary_accuracy: 0.9389\n",
      "Epoch 5/150\n",
      "2188/2188 [==============================] - 45s 20ms/step - loss: 0.1130 - binary_accuracy: 0.9560 - val_loss: 0.1543 - val_binary_accuracy: 0.9384\n",
      "Epoch 6/150\n",
      "2188/2188 [==============================] - 43s 19ms/step - loss: 0.1066 - binary_accuracy: 0.9579 - val_loss: 0.0982 - val_binary_accuracy: 0.9624\n",
      "Epoch 7/150\n",
      "2188/2188 [==============================] - 42s 19ms/step - loss: 0.1000 - binary_accuracy: 0.9605 - val_loss: 0.0937 - val_binary_accuracy: 0.9629\n",
      "Epoch 8/150\n",
      "2188/2188 [==============================] - 40s 18ms/step - loss: 0.0958 - binary_accuracy: 0.9624 - val_loss: 0.0969 - val_binary_accuracy: 0.9607\n",
      "Epoch 9/150\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.0904 - binary_accuracy: 0.9640 - val_loss: 0.0868 - val_binary_accuracy: 0.9661\n",
      "Epoch 10/150\n",
      "2188/2188 [==============================] - 41s 19ms/step - loss: 0.0865 - binary_accuracy: 0.9662 - val_loss: 0.0903 - val_binary_accuracy: 0.9656\n",
      "Epoch 11/150\n",
      "2188/2188 [==============================] - 48s 22ms/step - loss: 0.0821 - binary_accuracy: 0.9677 - val_loss: 0.0840 - val_binary_accuracy: 0.9669\n",
      "Epoch 12/150\n",
      "2188/2188 [==============================] - 30s 14ms/step - loss: 0.0797 - binary_accuracy: 0.9681 - val_loss: 0.0801 - val_binary_accuracy: 0.9691\n",
      "Epoch 13/150\n",
      "2188/2188 [==============================] - 21s 10ms/step - loss: 0.0757 - binary_accuracy: 0.9698 - val_loss: 0.0819 - val_binary_accuracy: 0.9677\n",
      "Epoch 14/150\n",
      "2188/2188 [==============================] - 19s 9ms/step - loss: 0.0731 - binary_accuracy: 0.9712 - val_loss: 0.0832 - val_binary_accuracy: 0.9681\n",
      "Epoch 15/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0700 - binary_accuracy: 0.9728 - val_loss: 0.0898 - val_binary_accuracy: 0.9650\n",
      "Epoch 16/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0684 - binary_accuracy: 0.9728 - val_loss: 0.0801 - val_binary_accuracy: 0.9695\n",
      "Epoch 17/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0673 - binary_accuracy: 0.9740 - val_loss: 0.0837 - val_binary_accuracy: 0.9651\n",
      "Epoch 18/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0643 - binary_accuracy: 0.9751 - val_loss: 0.0805 - val_binary_accuracy: 0.9690\n",
      "Epoch 19/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0632 - binary_accuracy: 0.9751 - val_loss: 0.0801 - val_binary_accuracy: 0.9680\n",
      "Epoch 20/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0610 - binary_accuracy: 0.9759 - val_loss: 0.0804 - val_binary_accuracy: 0.9686\n",
      "Epoch 21/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0593 - binary_accuracy: 0.9768 - val_loss: 0.0831 - val_binary_accuracy: 0.9682\n",
      "Epoch 22/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0580 - binary_accuracy: 0.9772 - val_loss: 0.0785 - val_binary_accuracy: 0.9690\n",
      "Epoch 23/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0568 - binary_accuracy: 0.9774 - val_loss: 0.0823 - val_binary_accuracy: 0.9684\n",
      "Epoch 24/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0563 - binary_accuracy: 0.9780 - val_loss: 0.0814 - val_binary_accuracy: 0.9695\n",
      "Epoch 25/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0549 - binary_accuracy: 0.9786 - val_loss: 0.0790 - val_binary_accuracy: 0.9705\n",
      "Epoch 26/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0541 - binary_accuracy: 0.9786 - val_loss: 0.0778 - val_binary_accuracy: 0.9697\n",
      "Epoch 27/150\n",
      "2188/2188 [==============================] - 19s 9ms/step - loss: 0.0524 - binary_accuracy: 0.9796 - val_loss: 0.0809 - val_binary_accuracy: 0.9699\n",
      "Epoch 28/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0523 - binary_accuracy: 0.9795 - val_loss: 0.0804 - val_binary_accuracy: 0.9690\n",
      "Epoch 29/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0518 - binary_accuracy: 0.9802 - val_loss: 0.0789 - val_binary_accuracy: 0.9699\n",
      "Epoch 30/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0509 - binary_accuracy: 0.9800 - val_loss: 0.0792 - val_binary_accuracy: 0.9709\n",
      "Epoch 31/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0507 - binary_accuracy: 0.9803 - val_loss: 0.0813 - val_binary_accuracy: 0.9692\n",
      "Epoch 32/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0498 - binary_accuracy: 0.9806 - val_loss: 0.0804 - val_binary_accuracy: 0.9701\n",
      "Epoch 33/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0493 - binary_accuracy: 0.9811 - val_loss: 0.0796 - val_binary_accuracy: 0.9701\n",
      "Epoch 34/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0486 - binary_accuracy: 0.9809 - val_loss: 0.0796 - val_binary_accuracy: 0.9701\n",
      "Epoch 35/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0485 - binary_accuracy: 0.9815 - val_loss: 0.0799 - val_binary_accuracy: 0.9702\n",
      "Epoch 36/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0482 - binary_accuracy: 0.9812 - val_loss: 0.0793 - val_binary_accuracy: 0.9706\n",
      "Epoch 37/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0477 - binary_accuracy: 0.9820 - val_loss: 0.0800 - val_binary_accuracy: 0.9707\n",
      "Epoch 38/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0476 - binary_accuracy: 0.9819 - val_loss: 0.0796 - val_binary_accuracy: 0.9706\n",
      "Epoch 39/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0475 - binary_accuracy: 0.9819 - val_loss: 0.0801 - val_binary_accuracy: 0.9703\n",
      "Epoch 40/150\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0471 - binary_accuracy: 0.9822 - val_loss: 0.0812 - val_binary_accuracy: 0.9691\n"
     ]
    }
   ],
   "source": [
    "history = nn_model.fit(X_train, y_train,\n",
    "             batch_size=batch_size,\n",
    "             epochs=num_epochs,\n",
    "             validation_data=(X_val, y_val),\n",
    "             callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"val_binary_accuracy\"])\n",
    "plt.plot(history.history[\"binary_accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0899 - binary_accuracy: 0.9687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9686999917030334"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model_roberta[\"neural_network\"] = nn_model.evaluate(X_test, y_test)[1]\n",
    "scores_model_roberta[\"neural_network\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_model_roberta-large_70000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_model_roberta-large_70000/assets\n"
     ]
    }
   ],
   "source": [
    "nn_model.save(f\"nn_model_{model_ckpt}_{train_size}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Prediction for input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression': 0.9624,\n",
       " 'ridge': 0.9591,\n",
       " 'neural_network': 0.9686999917030334}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super GT (stylized as SUPER GT) is a grand touring car racing series that began in 1993. Originally titled as the Zen Nihon GT Senshuken (全日本GT選手権), generally referred to as either the JGTC or the All Japan Grand Touring Car .... the Nissan Skyline GT-R, the Toyota Supra, and the Honda NSX represented their ...\n",
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15542404"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = ds_dict[\"test\"][\"text\"][5]\n",
    "print(test_text)\n",
    "nn_model.predict(model(**tokenizer(test_text, return_tensors='tf')).last_hidden_state[:,0].numpy())[0][0]\n",
    "#ridge_clf.decision_function(model(**tokenizer(test_text, return_tensors='tf')).last_hidden_state[:,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text_input: str, \n",
    "                   model_ckpt: str=\"distilbert-base-uncased\",\n",
    "                   train_size: int=70_000,\n",
    "                   model_name: str=\"nn\") -> tuple[float, str]:\n",
    "    '''outputs the probability of the text being AI written\n",
    "    ---\n",
    "    text_input: text to be classified\n",
    "    ---\n",
    "    model_ckpt: model to be used for feature extraction. Options are \"distilbert\"\n",
    "    and \"roberta\".\n",
    "    ---\n",
    "    model_name: model to be used for classification. Options are \"nn\" \n",
    "    for neural network, \"lr\" for logistic regression, \"ridge\" for ridge classifier.\n",
    "    '''\n",
    "    # instantiate tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f\"extractors_tokenizer_{model_ckpt}\")\n",
    "    model = TFAutoModel.from_pretrained(f'extractors_model_{model_ckpt}')\n",
    "    # extract features\n",
    "    inputs = tokenizer(text_input.replace(\"\\n\", \" \"), return_tensors=\"tf\")\n",
    "    outputs = model(**inputs)\n",
    "    hidden_states = outputs.last_hidden_state[:, 0].numpy()\n",
    "    # choose model for classification and return prediction and probability\n",
    "    proba = None\n",
    "    class_pred = None\n",
    "    if model_name == \"nn\":\n",
    "        nn_model = keras.models.load_model(f\"nn_model_{model_ckpt}_{train_size}\")\n",
    "        proba = nn_model.predict(hidden_states, verbose=0)[0][0]\n",
    "    elif model_name == \"lr\":\n",
    "        lr_clf_best = load(f\"trained_models_{train_size}/lr_clf_best_{model_ckpt}.joblib\")\n",
    "        proba = lr_clf_best.predict_proba(hidden_states)[0][1]\n",
    "    elif model_name == \"ridge\":\n",
    "        ridge_clf = load(f\"trained_models_{train_size}/ridge_clf_{model_ckpt}.joblib\")\n",
    "        decision = ridge_clf.decision_function(hidden_states)[0]\n",
    "        proba = np.exp(decision)/(1+np.exp(decision)) # be careful with this (probabilities are not calibrated)\n",
    "    # elif model_name == \"xgb\": # xgboost takes too much CPU and RAM\n",
    "    #     xgb_best = load(f\"trained_models/xgb_best_{model_ckpt}.joblib.dat\")\n",
    "    #     proba = xgb_best.predict_proba(hidden_states)[0][1]\n",
    "    else:\n",
    "        raise ValueError(\"model must be one of 'nn', 'lr' or 'ridge'\")\n",
    "    if proba > 0.5:\n",
    "        class_pred = \"AI written\"\n",
    "    else:\n",
    "        class_pred = \"not AI written\"\n",
    "    print(f'Probability of text being AI written: {proba:.2f}. \\nThe prediction therfore is that the text is {class_pred}.')\n",
    "    return proba, class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of text being AI written: 0.16. \n",
      "The prediction therfore is that the text is not AI written.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 15:53:14.510001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15542404, 'not AI written')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(test_text, model_ckpt=\"roberta-large\", \n",
    "               train_size = 70000, model_name=\"nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headline: Political Tensions Rise as Election ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the current political climate, tensions are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In a heated political scene, tensions rise as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the midst of a tumultuous political climate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the midst of a global pandemic, politics co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>The educational system of Finland has been wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Recently, there has been a lot of attention on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Sweden's Educational System: A Model for the W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>In recent years, the educational system of Fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Sweden's Educational System: A Model for Europ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  AI\n",
       "0    Headline: Political Tensions Rise as Election ...   1\n",
       "1    In the current political climate, tensions are...   1\n",
       "2    In a heated political scene, tensions rise as ...   1\n",
       "3    In the midst of a tumultuous political climate...   1\n",
       "4    In the midst of a global pandemic, politics co...   1\n",
       "..                                                 ...  ..\n",
       "245  The educational system of Finland has been wid...   1\n",
       "246  Recently, there has been a lot of attention on...   1\n",
       "247  Sweden's Educational System: A Model for the W...   1\n",
       "248  In recent years, the educational system of Fin...   1\n",
       "249  Sweden's Educational System: A Model for Europ...   1\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = pd.read_csv(\"gpt3_output/demo_data.csv\")\n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of text being AI written: 1.00. \n",
      "The prediction therfore is that the text is AI written.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 16:22:07.153137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9999782, 'AI written')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(demo.text[25], model_ckpt=\"roberta-large\",\n",
    "               train_size=70000, model_name=\"nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_written_text_identifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
